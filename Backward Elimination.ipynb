{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b81924d9",
   "metadata": {},
   "source": [
    "Backward elimination is a feature selection technique while building a machine learning model. It is used to remove those features that do not have a significant effect on the dependent variable or prediction of output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c331b",
   "metadata": {},
   "source": [
    "Steps of Backward Elimination:\n",
    "\n",
    "Step-1: Firstly, We need to select a significance level to stay in the model. (SL=0.05)\n",
    "Step-2: Fit the complete model with all possible predictors/independent variables.\n",
    "\n",
    "Step-3: Choose the predictor which has the highest P-value, such that.\n",
    "\n",
    "If P-value >SL, go to step 4.\n",
    "Else Finish, and Our model is ready.\n",
    "Step-4: Remove that predictor.\n",
    "\n",
    "Step-5: Rebuild and fit the model with the remaining variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f21cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad24a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=pd.read_csv('50_Startups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06d58e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>New York</td>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>California</td>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>Florida</td>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>California</td>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>Florida</td>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>California</td>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>Florida</td>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>California</td>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>Florida</td>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>California</td>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>New York</td>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>Florida</td>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>California</td>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>Florida</td>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>Florida</td>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>California</td>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>Florida</td>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>Florida</td>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>New York</td>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>Florida</td>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>California</td>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>Florida</td>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>California</td>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>New York</td>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>Florida</td>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>California</td>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>California</td>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>California</td>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>Florida</td>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>California</td>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>New York</td>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>California</td>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>New York</td>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>Florida</td>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>California</td>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>California</td>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0   165349.20       136897.80        471784.10    New York  192261.83\n",
       "1   162597.70       151377.59        443898.53  California  191792.06\n",
       "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3   144372.41       118671.85        383199.62    New York  182901.99\n",
       "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
       "5   131876.90        99814.71        362861.36    New York  156991.12\n",
       "6   134615.46       147198.87        127716.82  California  156122.51\n",
       "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
       "8   120542.52       148718.95        311613.29    New York  152211.77\n",
       "9   123334.88       108679.17        304981.62  California  149759.96\n",
       "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
       "11  100671.96        91790.61        249744.55  California  144259.40\n",
       "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
       "13   91992.39       135495.07        252664.93  California  134307.35\n",
       "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
       "15  114523.61       122616.84        261776.23    New York  129917.04\n",
       "16   78013.11       121597.55        264346.06  California  126992.93\n",
       "17   94657.16       145077.58        282574.31    New York  125370.37\n",
       "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
       "19   86419.70       153514.11             0.00    New York  122776.86\n",
       "20   76253.86       113867.30        298664.47  California  118474.03\n",
       "21   78389.47       153773.43        299737.29    New York  111313.02\n",
       "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
       "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
       "24   77044.01        99281.34        140574.81    New York  108552.04\n",
       "25   64664.71       139553.16        137962.62  California  107404.34\n",
       "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
       "27   72107.60       127864.55        353183.81    New York  105008.31\n",
       "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
       "29   65605.48       153032.06        107138.38    New York  101004.64\n",
       "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
       "31   61136.38       152701.92         88218.23    New York   97483.56\n",
       "32   63408.86       129219.61         46085.25  California   97427.84\n",
       "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
       "34   46426.07       157693.92        210797.67  California   96712.80\n",
       "35   46014.02        85047.44        205517.64    New York   96479.51\n",
       "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
       "37   44069.95        51283.14        197029.42  California   89949.14\n",
       "38   20229.59        65947.93        185265.10    New York   81229.06\n",
       "39   38558.51        82982.09        174999.30  California   81005.76\n",
       "40   28754.33       118546.05        172795.67  California   78239.91\n",
       "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
       "42   23640.93        96189.63        148001.11  California   71498.49\n",
       "43   15505.73       127382.30         35534.17    New York   69758.98\n",
       "44   22177.74       154806.14         28334.72  California   65200.33\n",
       "45    1000.23       124153.04          1903.93    New York   64926.08\n",
       "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
       "47       0.00       135426.92             0.00  California   42559.73\n",
       "48     542.05        51743.15             0.00    New York   35673.41\n",
       "49       0.00       116983.80         45173.06  California   14681.40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a2ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Independent and dependent Variable  \n",
    "x=data_set.iloc[:,:-1].values\n",
    "y=data_set.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ccadc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165349.2, 136897.8, 471784.1, 'New York'],\n",
       "       [162597.7, 151377.59, 443898.53, 'California'],\n",
       "       [153441.51, 101145.55, 407934.54, 'Florida'],\n",
       "       [144372.41, 118671.85, 383199.62, 'New York'],\n",
       "       [142107.34, 91391.77, 366168.42, 'Florida'],\n",
       "       [131876.9, 99814.71, 362861.36, 'New York'],\n",
       "       [134615.46, 147198.87, 127716.82, 'California'],\n",
       "       [130298.13, 145530.06, 323876.68, 'Florida'],\n",
       "       [120542.52, 148718.95, 311613.29, 'New York'],\n",
       "       [123334.88, 108679.17, 304981.62, 'California'],\n",
       "       [101913.08, 110594.11, 229160.95, 'Florida'],\n",
       "       [100671.96, 91790.61, 249744.55, 'California'],\n",
       "       [93863.75, 127320.38, 249839.44, 'Florida'],\n",
       "       [91992.39, 135495.07, 252664.93, 'California'],\n",
       "       [119943.24, 156547.42, 256512.92, 'Florida'],\n",
       "       [114523.61, 122616.84, 261776.23, 'New York'],\n",
       "       [78013.11, 121597.55, 264346.06, 'California'],\n",
       "       [94657.16, 145077.58, 282574.31, 'New York'],\n",
       "       [91749.16, 114175.79, 294919.57, 'Florida'],\n",
       "       [86419.7, 153514.11, 0.0, 'New York'],\n",
       "       [76253.86, 113867.3, 298664.47, 'California'],\n",
       "       [78389.47, 153773.43, 299737.29, 'New York'],\n",
       "       [73994.56, 122782.75, 303319.26, 'Florida'],\n",
       "       [67532.53, 105751.03, 304768.73, 'Florida'],\n",
       "       [77044.01, 99281.34, 140574.81, 'New York'],\n",
       "       [64664.71, 139553.16, 137962.62, 'California'],\n",
       "       [75328.87, 144135.98, 134050.07, 'Florida'],\n",
       "       [72107.6, 127864.55, 353183.81, 'New York'],\n",
       "       [66051.52, 182645.56, 118148.2, 'Florida'],\n",
       "       [65605.48, 153032.06, 107138.38, 'New York'],\n",
       "       [61994.48, 115641.28, 91131.24, 'Florida'],\n",
       "       [61136.38, 152701.92, 88218.23, 'New York'],\n",
       "       [63408.86, 129219.61, 46085.25, 'California'],\n",
       "       [55493.95, 103057.49, 214634.81, 'Florida'],\n",
       "       [46426.07, 157693.92, 210797.67, 'California'],\n",
       "       [46014.02, 85047.44, 205517.64, 'New York'],\n",
       "       [28663.76, 127056.21, 201126.82, 'Florida'],\n",
       "       [44069.95, 51283.14, 197029.42, 'California'],\n",
       "       [20229.59, 65947.93, 185265.1, 'New York'],\n",
       "       [38558.51, 82982.09, 174999.3, 'California'],\n",
       "       [28754.33, 118546.05, 172795.67, 'California'],\n",
       "       [27892.92, 84710.77, 164470.71, 'Florida'],\n",
       "       [23640.93, 96189.63, 148001.11, 'California'],\n",
       "       [15505.73, 127382.3, 35534.17, 'New York'],\n",
       "       [22177.74, 154806.14, 28334.72, 'California'],\n",
       "       [1000.23, 124153.04, 1903.93, 'New York'],\n",
       "       [1315.46, 115816.21, 297114.46, 'Florida'],\n",
       "       [0.0, 135426.92, 0.0, 'California'],\n",
       "       [542.05, 51743.15, 0.0, 'New York'],\n",
       "       [0.0, 116983.8, 45173.06, 'California']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4447d878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192261.83, 191792.06, 191050.39, 182901.99, 166187.94, 156991.12,\n",
       "       156122.51, 155752.6 , 152211.77, 149759.96, 146121.95, 144259.4 ,\n",
       "       141585.52, 134307.35, 132602.65, 129917.04, 126992.93, 125370.37,\n",
       "       124266.9 , 122776.86, 118474.03, 111313.02, 110352.25, 108733.99,\n",
       "       108552.04, 107404.34, 105733.54, 105008.31, 103282.38, 101004.64,\n",
       "        99937.59,  97483.56,  97427.84,  96778.92,  96712.8 ,  96479.51,\n",
       "        90708.19,  89949.14,  81229.06,  81005.76,  78239.91,  77798.83,\n",
       "        71498.49,  69758.98,  65200.33,  64926.08,  49490.75,  42559.73,\n",
       "        35673.41,  14681.4 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd06202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20bfdcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[3])],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "531b61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_x=ct1.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce0058f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encoded data to dataframe\n",
    "encoded_df1_x=pd.DataFrame(encoded_data_x,columns=ct1.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3003187a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder__x3_California</th>\n",
       "      <th>encoder__x3_Florida</th>\n",
       "      <th>encoder__x3_New York</th>\n",
       "      <th>remainder__x0</th>\n",
       "      <th>remainder__x1</th>\n",
       "      <th>remainder__x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165349.2</td>\n",
       "      <td>136897.8</td>\n",
       "      <td>471784.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162597.7</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131876.9</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86419.7</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.3</td>\n",
       "      <td>298664.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72107.6</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.3</td>\n",
       "      <td>35534.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116983.8</td>\n",
       "      <td>45173.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoder__x3_California encoder__x3_Florida encoder__x3_New York  \\\n",
       "0                     0.0                 0.0                  1.0   \n",
       "1                     1.0                 0.0                  0.0   \n",
       "2                     0.0                 1.0                  0.0   \n",
       "3                     0.0                 0.0                  1.0   \n",
       "4                     0.0                 1.0                  0.0   \n",
       "5                     0.0                 0.0                  1.0   \n",
       "6                     1.0                 0.0                  0.0   \n",
       "7                     0.0                 1.0                  0.0   \n",
       "8                     0.0                 0.0                  1.0   \n",
       "9                     1.0                 0.0                  0.0   \n",
       "10                    0.0                 1.0                  0.0   \n",
       "11                    1.0                 0.0                  0.0   \n",
       "12                    0.0                 1.0                  0.0   \n",
       "13                    1.0                 0.0                  0.0   \n",
       "14                    0.0                 1.0                  0.0   \n",
       "15                    0.0                 0.0                  1.0   \n",
       "16                    1.0                 0.0                  0.0   \n",
       "17                    0.0                 0.0                  1.0   \n",
       "18                    0.0                 1.0                  0.0   \n",
       "19                    0.0                 0.0                  1.0   \n",
       "20                    1.0                 0.0                  0.0   \n",
       "21                    0.0                 0.0                  1.0   \n",
       "22                    0.0                 1.0                  0.0   \n",
       "23                    0.0                 1.0                  0.0   \n",
       "24                    0.0                 0.0                  1.0   \n",
       "25                    1.0                 0.0                  0.0   \n",
       "26                    0.0                 1.0                  0.0   \n",
       "27                    0.0                 0.0                  1.0   \n",
       "28                    0.0                 1.0                  0.0   \n",
       "29                    0.0                 0.0                  1.0   \n",
       "30                    0.0                 1.0                  0.0   \n",
       "31                    0.0                 0.0                  1.0   \n",
       "32                    1.0                 0.0                  0.0   \n",
       "33                    0.0                 1.0                  0.0   \n",
       "34                    1.0                 0.0                  0.0   \n",
       "35                    0.0                 0.0                  1.0   \n",
       "36                    0.0                 1.0                  0.0   \n",
       "37                    1.0                 0.0                  0.0   \n",
       "38                    0.0                 0.0                  1.0   \n",
       "39                    1.0                 0.0                  0.0   \n",
       "40                    1.0                 0.0                  0.0   \n",
       "41                    0.0                 1.0                  0.0   \n",
       "42                    1.0                 0.0                  0.0   \n",
       "43                    0.0                 0.0                  1.0   \n",
       "44                    1.0                 0.0                  0.0   \n",
       "45                    0.0                 0.0                  1.0   \n",
       "46                    0.0                 1.0                  0.0   \n",
       "47                    1.0                 0.0                  0.0   \n",
       "48                    0.0                 0.0                  1.0   \n",
       "49                    1.0                 0.0                  0.0   \n",
       "\n",
       "   remainder__x0 remainder__x1 remainder__x2  \n",
       "0       165349.2      136897.8      471784.1  \n",
       "1       162597.7     151377.59     443898.53  \n",
       "2      153441.51     101145.55     407934.54  \n",
       "3      144372.41     118671.85     383199.62  \n",
       "4      142107.34      91391.77     366168.42  \n",
       "5       131876.9      99814.71     362861.36  \n",
       "6      134615.46     147198.87     127716.82  \n",
       "7      130298.13     145530.06     323876.68  \n",
       "8      120542.52     148718.95     311613.29  \n",
       "9      123334.88     108679.17     304981.62  \n",
       "10     101913.08     110594.11     229160.95  \n",
       "11     100671.96      91790.61     249744.55  \n",
       "12      93863.75     127320.38     249839.44  \n",
       "13      91992.39     135495.07     252664.93  \n",
       "14     119943.24     156547.42     256512.92  \n",
       "15     114523.61     122616.84     261776.23  \n",
       "16      78013.11     121597.55     264346.06  \n",
       "17      94657.16     145077.58     282574.31  \n",
       "18      91749.16     114175.79     294919.57  \n",
       "19       86419.7     153514.11           0.0  \n",
       "20      76253.86      113867.3     298664.47  \n",
       "21      78389.47     153773.43     299737.29  \n",
       "22      73994.56     122782.75     303319.26  \n",
       "23      67532.53     105751.03     304768.73  \n",
       "24      77044.01      99281.34     140574.81  \n",
       "25      64664.71     139553.16     137962.62  \n",
       "26      75328.87     144135.98     134050.07  \n",
       "27       72107.6     127864.55     353183.81  \n",
       "28      66051.52     182645.56      118148.2  \n",
       "29      65605.48     153032.06     107138.38  \n",
       "30      61994.48     115641.28      91131.24  \n",
       "31      61136.38     152701.92      88218.23  \n",
       "32      63408.86     129219.61      46085.25  \n",
       "33      55493.95     103057.49     214634.81  \n",
       "34      46426.07     157693.92     210797.67  \n",
       "35      46014.02      85047.44     205517.64  \n",
       "36      28663.76     127056.21     201126.82  \n",
       "37      44069.95      51283.14     197029.42  \n",
       "38      20229.59      65947.93      185265.1  \n",
       "39      38558.51      82982.09      174999.3  \n",
       "40      28754.33     118546.05     172795.67  \n",
       "41      27892.92      84710.77     164470.71  \n",
       "42      23640.93      96189.63     148001.11  \n",
       "43      15505.73      127382.3      35534.17  \n",
       "44      22177.74     154806.14      28334.72  \n",
       "45       1000.23     124153.04       1903.93  \n",
       "46       1315.46     115816.21     297114.46  \n",
       "47           0.0     135426.92           0.0  \n",
       "48        542.05      51743.15           0.0  \n",
       "49           0.0      116983.8      45173.06  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df1_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "932ce964",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df1_x.columns = ['California', 'Florida','NewYork','R&D Spend','Administration','Marketing Spend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "226fe989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Florida</th>\n",
       "      <th>NewYork</th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165349.2</td>\n",
       "      <td>136897.8</td>\n",
       "      <td>471784.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162597.7</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131876.9</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86419.7</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.3</td>\n",
       "      <td>298664.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72107.6</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.3</td>\n",
       "      <td>35534.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116983.8</td>\n",
       "      <td>45173.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California Florida NewYork  R&D Spend Administration Marketing Spend\n",
       "0         0.0     0.0     1.0   165349.2       136897.8        471784.1\n",
       "1         1.0     0.0     0.0   162597.7      151377.59       443898.53\n",
       "2         0.0     1.0     0.0  153441.51      101145.55       407934.54\n",
       "3         0.0     0.0     1.0  144372.41      118671.85       383199.62\n",
       "4         0.0     1.0     0.0  142107.34       91391.77       366168.42\n",
       "5         0.0     0.0     1.0   131876.9       99814.71       362861.36\n",
       "6         1.0     0.0     0.0  134615.46      147198.87       127716.82\n",
       "7         0.0     1.0     0.0  130298.13      145530.06       323876.68\n",
       "8         0.0     0.0     1.0  120542.52      148718.95       311613.29\n",
       "9         1.0     0.0     0.0  123334.88      108679.17       304981.62\n",
       "10        0.0     1.0     0.0  101913.08      110594.11       229160.95\n",
       "11        1.0     0.0     0.0  100671.96       91790.61       249744.55\n",
       "12        0.0     1.0     0.0   93863.75      127320.38       249839.44\n",
       "13        1.0     0.0     0.0   91992.39      135495.07       252664.93\n",
       "14        0.0     1.0     0.0  119943.24      156547.42       256512.92\n",
       "15        0.0     0.0     1.0  114523.61      122616.84       261776.23\n",
       "16        1.0     0.0     0.0   78013.11      121597.55       264346.06\n",
       "17        0.0     0.0     1.0   94657.16      145077.58       282574.31\n",
       "18        0.0     1.0     0.0   91749.16      114175.79       294919.57\n",
       "19        0.0     0.0     1.0    86419.7      153514.11             0.0\n",
       "20        1.0     0.0     0.0   76253.86       113867.3       298664.47\n",
       "21        0.0     0.0     1.0   78389.47      153773.43       299737.29\n",
       "22        0.0     1.0     0.0   73994.56      122782.75       303319.26\n",
       "23        0.0     1.0     0.0   67532.53      105751.03       304768.73\n",
       "24        0.0     0.0     1.0   77044.01       99281.34       140574.81\n",
       "25        1.0     0.0     0.0   64664.71      139553.16       137962.62\n",
       "26        0.0     1.0     0.0   75328.87      144135.98       134050.07\n",
       "27        0.0     0.0     1.0    72107.6      127864.55       353183.81\n",
       "28        0.0     1.0     0.0   66051.52      182645.56        118148.2\n",
       "29        0.0     0.0     1.0   65605.48      153032.06       107138.38\n",
       "30        0.0     1.0     0.0   61994.48      115641.28        91131.24\n",
       "31        0.0     0.0     1.0   61136.38      152701.92        88218.23\n",
       "32        1.0     0.0     0.0   63408.86      129219.61        46085.25\n",
       "33        0.0     1.0     0.0   55493.95      103057.49       214634.81\n",
       "34        1.0     0.0     0.0   46426.07      157693.92       210797.67\n",
       "35        0.0     0.0     1.0   46014.02       85047.44       205517.64\n",
       "36        0.0     1.0     0.0   28663.76      127056.21       201126.82\n",
       "37        1.0     0.0     0.0   44069.95       51283.14       197029.42\n",
       "38        0.0     0.0     1.0   20229.59       65947.93        185265.1\n",
       "39        1.0     0.0     0.0   38558.51       82982.09        174999.3\n",
       "40        1.0     0.0     0.0   28754.33      118546.05       172795.67\n",
       "41        0.0     1.0     0.0   27892.92       84710.77       164470.71\n",
       "42        1.0     0.0     0.0   23640.93       96189.63       148001.11\n",
       "43        0.0     0.0     1.0   15505.73       127382.3        35534.17\n",
       "44        1.0     0.0     0.0   22177.74      154806.14        28334.72\n",
       "45        0.0     0.0     1.0    1000.23      124153.04         1903.93\n",
       "46        0.0     1.0     0.0    1315.46      115816.21       297114.46\n",
       "47        1.0     0.0     0.0        0.0      135426.92             0.0\n",
       "48        0.0     0.0     1.0     542.05       51743.15             0.0\n",
       "49        1.0     0.0     0.0        0.0       116983.8        45173.06"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df1_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b2b9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoiding the dummy variable trap:  \n",
    "encoded_df1_x= encoded_df1_x.drop(['California'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6be09a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df1_x = encoded_df1_x.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bad3b811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Florida</th>\n",
       "      <th>NewYork</th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165349</td>\n",
       "      <td>136897</td>\n",
       "      <td>471784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162597</td>\n",
       "      <td>151377</td>\n",
       "      <td>443898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153441</td>\n",
       "      <td>101145</td>\n",
       "      <td>407934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144372</td>\n",
       "      <td>118671</td>\n",
       "      <td>383199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>142107</td>\n",
       "      <td>91391</td>\n",
       "      <td>366168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131876</td>\n",
       "      <td>99814</td>\n",
       "      <td>362861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134615</td>\n",
       "      <td>147198</td>\n",
       "      <td>127716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130298</td>\n",
       "      <td>145530</td>\n",
       "      <td>323876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120542</td>\n",
       "      <td>148718</td>\n",
       "      <td>311613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123334</td>\n",
       "      <td>108679</td>\n",
       "      <td>304981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101913</td>\n",
       "      <td>110594</td>\n",
       "      <td>229160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100671</td>\n",
       "      <td>91790</td>\n",
       "      <td>249744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93863</td>\n",
       "      <td>127320</td>\n",
       "      <td>249839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91992</td>\n",
       "      <td>135495</td>\n",
       "      <td>252664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119943</td>\n",
       "      <td>156547</td>\n",
       "      <td>256512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114523</td>\n",
       "      <td>122616</td>\n",
       "      <td>261776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78013</td>\n",
       "      <td>121597</td>\n",
       "      <td>264346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>94657</td>\n",
       "      <td>145077</td>\n",
       "      <td>282574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91749</td>\n",
       "      <td>114175</td>\n",
       "      <td>294919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>86419</td>\n",
       "      <td>153514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76253</td>\n",
       "      <td>113867</td>\n",
       "      <td>298664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78389</td>\n",
       "      <td>153773</td>\n",
       "      <td>299737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73994</td>\n",
       "      <td>122782</td>\n",
       "      <td>303319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67532</td>\n",
       "      <td>105751</td>\n",
       "      <td>304768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77044</td>\n",
       "      <td>99281</td>\n",
       "      <td>140574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64664</td>\n",
       "      <td>139553</td>\n",
       "      <td>137962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75328</td>\n",
       "      <td>144135</td>\n",
       "      <td>134050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72107</td>\n",
       "      <td>127864</td>\n",
       "      <td>353183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66051</td>\n",
       "      <td>182645</td>\n",
       "      <td>118148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65605</td>\n",
       "      <td>153032</td>\n",
       "      <td>107138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61994</td>\n",
       "      <td>115641</td>\n",
       "      <td>91131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61136</td>\n",
       "      <td>152701</td>\n",
       "      <td>88218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63408</td>\n",
       "      <td>129219</td>\n",
       "      <td>46085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55493</td>\n",
       "      <td>103057</td>\n",
       "      <td>214634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46426</td>\n",
       "      <td>157693</td>\n",
       "      <td>210797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46014</td>\n",
       "      <td>85047</td>\n",
       "      <td>205517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28663</td>\n",
       "      <td>127056</td>\n",
       "      <td>201126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44069</td>\n",
       "      <td>51283</td>\n",
       "      <td>197029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20229</td>\n",
       "      <td>65947</td>\n",
       "      <td>185265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38558</td>\n",
       "      <td>82982</td>\n",
       "      <td>174999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28754</td>\n",
       "      <td>118546</td>\n",
       "      <td>172795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27892</td>\n",
       "      <td>84710</td>\n",
       "      <td>164470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23640</td>\n",
       "      <td>96189</td>\n",
       "      <td>148001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15505</td>\n",
       "      <td>127382</td>\n",
       "      <td>35534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22177</td>\n",
       "      <td>154806</td>\n",
       "      <td>28334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>124153</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1315</td>\n",
       "      <td>115816</td>\n",
       "      <td>297114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>542</td>\n",
       "      <td>51743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116983</td>\n",
       "      <td>45173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Florida  NewYork  R&D Spend  Administration  Marketing Spend\n",
       "0         0        1     165349          136897           471784\n",
       "1         0        0     162597          151377           443898\n",
       "2         1        0     153441          101145           407934\n",
       "3         0        1     144372          118671           383199\n",
       "4         1        0     142107           91391           366168\n",
       "5         0        1     131876           99814           362861\n",
       "6         0        0     134615          147198           127716\n",
       "7         1        0     130298          145530           323876\n",
       "8         0        1     120542          148718           311613\n",
       "9         0        0     123334          108679           304981\n",
       "10        1        0     101913          110594           229160\n",
       "11        0        0     100671           91790           249744\n",
       "12        1        0      93863          127320           249839\n",
       "13        0        0      91992          135495           252664\n",
       "14        1        0     119943          156547           256512\n",
       "15        0        1     114523          122616           261776\n",
       "16        0        0      78013          121597           264346\n",
       "17        0        1      94657          145077           282574\n",
       "18        1        0      91749          114175           294919\n",
       "19        0        1      86419          153514                0\n",
       "20        0        0      76253          113867           298664\n",
       "21        0        1      78389          153773           299737\n",
       "22        1        0      73994          122782           303319\n",
       "23        1        0      67532          105751           304768\n",
       "24        0        1      77044           99281           140574\n",
       "25        0        0      64664          139553           137962\n",
       "26        1        0      75328          144135           134050\n",
       "27        0        1      72107          127864           353183\n",
       "28        1        0      66051          182645           118148\n",
       "29        0        1      65605          153032           107138\n",
       "30        1        0      61994          115641            91131\n",
       "31        0        1      61136          152701            88218\n",
       "32        0        0      63408          129219            46085\n",
       "33        1        0      55493          103057           214634\n",
       "34        0        0      46426          157693           210797\n",
       "35        0        1      46014           85047           205517\n",
       "36        1        0      28663          127056           201126\n",
       "37        0        0      44069           51283           197029\n",
       "38        0        1      20229           65947           185265\n",
       "39        0        0      38558           82982           174999\n",
       "40        0        0      28754          118546           172795\n",
       "41        1        0      27892           84710           164470\n",
       "42        0        0      23640           96189           148001\n",
       "43        0        1      15505          127382            35534\n",
       "44        0        0      22177          154806            28334\n",
       "45        0        1       1000          124153             1903\n",
       "46        1        0       1315          115816           297114\n",
       "47        0        0          0          135426                0\n",
       "48        0        1        542           51743                0\n",
       "49        0        0          0          116983            45173"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df1_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b7b1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(encoded_df1_x, y, test_size= 0.2, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9269f2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Florida</th>\n",
       "      <th>NewYork</th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93863</td>\n",
       "      <td>127320</td>\n",
       "      <td>249839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>142107</td>\n",
       "      <td>91391</td>\n",
       "      <td>366168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44069</td>\n",
       "      <td>51283</td>\n",
       "      <td>197029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120542</td>\n",
       "      <td>148718</td>\n",
       "      <td>311613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144372</td>\n",
       "      <td>118671</td>\n",
       "      <td>383199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Florida  NewYork  R&D Spend  Administration  Marketing Spend\n",
       "12        1        0      93863          127320           249839\n",
       "4         1        0     142107           91391           366168\n",
       "37        0        0      44069           51283           197029\n",
       "8         0        1     120542          148718           311613\n",
       "3         0        1     144372          118671           383199"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7caf42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([141585.52, 166187.94,  89949.14, 152211.77, 182901.99, 156122.51,\n",
       "        77798.83,  49490.75,  42559.73, 129917.04, 149759.96, 126992.93,\n",
       "       108552.04,  96712.8 ,  97483.56, 192261.83,  65200.33, 105008.31,\n",
       "        96778.92, 156991.12, 101004.64, 144259.4 ,  90708.19, 191792.06,\n",
       "       111313.02, 191050.39,  69758.98,  96479.51, 108733.99,  78239.91,\n",
       "       146121.95, 110352.25, 124266.9 ,  14681.4 , 118474.03, 155752.6 ,\n",
       "        71498.49, 132602.65, 103282.38,  81229.06])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9acf0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the MLR model to the training set:  \n",
    "from sklearn.linear_model import LinearRegression  \n",
    "regressor= LinearRegression()  \n",
    "regressor.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c02a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the Test set result;  \n",
    "y_pred= regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "825046e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9537015031120023\n",
      "Test Score:  0.8987245306209188\n"
     ]
    }
   ],
   "source": [
    "print('Train Score: ', regressor.score(x_train, y_train))  \n",
    "print('Test Score: ', regressor.score(x_test, y_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "520030e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05497535809286935"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The difference between both scores is \n",
    "0.9537019995248526-0.8987266414319832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b585d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as smf \n",
    "#library, which is used for the estimation of various statistical models such as OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa556f0c",
   "metadata": {},
   "source": [
    "Adding a column in matrix of features: As we can check in our MLR equation (a), there is one constant term b0, but this term is not present in our matrix of features, so we need to add it manually. We will add a column having values x0 = 1 associated with the constant term b0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd135a",
   "metadata": {},
   "source": [
    "To add this, we will use append function of Numpy library and will assign a value of 1. Below is the code for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e64168e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_df1_x=np.append(arr=np.ones((50,1)).astype(int),values=x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "375ce845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Florida</th>\n",
       "      <th>NewYork</th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165349</td>\n",
       "      <td>136897</td>\n",
       "      <td>471784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162597</td>\n",
       "      <td>151377</td>\n",
       "      <td>443898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153441</td>\n",
       "      <td>101145</td>\n",
       "      <td>407934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144372</td>\n",
       "      <td>118671</td>\n",
       "      <td>383199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>142107</td>\n",
       "      <td>91391</td>\n",
       "      <td>366168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131876</td>\n",
       "      <td>99814</td>\n",
       "      <td>362861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134615</td>\n",
       "      <td>147198</td>\n",
       "      <td>127716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130298</td>\n",
       "      <td>145530</td>\n",
       "      <td>323876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120542</td>\n",
       "      <td>148718</td>\n",
       "      <td>311613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123334</td>\n",
       "      <td>108679</td>\n",
       "      <td>304981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101913</td>\n",
       "      <td>110594</td>\n",
       "      <td>229160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100671</td>\n",
       "      <td>91790</td>\n",
       "      <td>249744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93863</td>\n",
       "      <td>127320</td>\n",
       "      <td>249839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91992</td>\n",
       "      <td>135495</td>\n",
       "      <td>252664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119943</td>\n",
       "      <td>156547</td>\n",
       "      <td>256512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114523</td>\n",
       "      <td>122616</td>\n",
       "      <td>261776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78013</td>\n",
       "      <td>121597</td>\n",
       "      <td>264346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>94657</td>\n",
       "      <td>145077</td>\n",
       "      <td>282574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91749</td>\n",
       "      <td>114175</td>\n",
       "      <td>294919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>86419</td>\n",
       "      <td>153514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76253</td>\n",
       "      <td>113867</td>\n",
       "      <td>298664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78389</td>\n",
       "      <td>153773</td>\n",
       "      <td>299737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73994</td>\n",
       "      <td>122782</td>\n",
       "      <td>303319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67532</td>\n",
       "      <td>105751</td>\n",
       "      <td>304768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77044</td>\n",
       "      <td>99281</td>\n",
       "      <td>140574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64664</td>\n",
       "      <td>139553</td>\n",
       "      <td>137962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75328</td>\n",
       "      <td>144135</td>\n",
       "      <td>134050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72107</td>\n",
       "      <td>127864</td>\n",
       "      <td>353183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66051</td>\n",
       "      <td>182645</td>\n",
       "      <td>118148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65605</td>\n",
       "      <td>153032</td>\n",
       "      <td>107138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61994</td>\n",
       "      <td>115641</td>\n",
       "      <td>91131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61136</td>\n",
       "      <td>152701</td>\n",
       "      <td>88218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63408</td>\n",
       "      <td>129219</td>\n",
       "      <td>46085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55493</td>\n",
       "      <td>103057</td>\n",
       "      <td>214634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46426</td>\n",
       "      <td>157693</td>\n",
       "      <td>210797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46014</td>\n",
       "      <td>85047</td>\n",
       "      <td>205517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28663</td>\n",
       "      <td>127056</td>\n",
       "      <td>201126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44069</td>\n",
       "      <td>51283</td>\n",
       "      <td>197029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20229</td>\n",
       "      <td>65947</td>\n",
       "      <td>185265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38558</td>\n",
       "      <td>82982</td>\n",
       "      <td>174999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28754</td>\n",
       "      <td>118546</td>\n",
       "      <td>172795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27892</td>\n",
       "      <td>84710</td>\n",
       "      <td>164470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23640</td>\n",
       "      <td>96189</td>\n",
       "      <td>148001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15505</td>\n",
       "      <td>127382</td>\n",
       "      <td>35534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22177</td>\n",
       "      <td>154806</td>\n",
       "      <td>28334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>124153</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1315</td>\n",
       "      <td>115816</td>\n",
       "      <td>297114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>542</td>\n",
       "      <td>51743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116983</td>\n",
       "      <td>45173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Florida  NewYork  R&D Spend  Administration  Marketing Spend\n",
       "0         0        1     165349          136897           471784\n",
       "1         0        0     162597          151377           443898\n",
       "2         1        0     153441          101145           407934\n",
       "3         0        1     144372          118671           383199\n",
       "4         1        0     142107           91391           366168\n",
       "5         0        1     131876           99814           362861\n",
       "6         0        0     134615          147198           127716\n",
       "7         1        0     130298          145530           323876\n",
       "8         0        1     120542          148718           311613\n",
       "9         0        0     123334          108679           304981\n",
       "10        1        0     101913          110594           229160\n",
       "11        0        0     100671           91790           249744\n",
       "12        1        0      93863          127320           249839\n",
       "13        0        0      91992          135495           252664\n",
       "14        1        0     119943          156547           256512\n",
       "15        0        1     114523          122616           261776\n",
       "16        0        0      78013          121597           264346\n",
       "17        0        1      94657          145077           282574\n",
       "18        1        0      91749          114175           294919\n",
       "19        0        1      86419          153514                0\n",
       "20        0        0      76253          113867           298664\n",
       "21        0        1      78389          153773           299737\n",
       "22        1        0      73994          122782           303319\n",
       "23        1        0      67532          105751           304768\n",
       "24        0        1      77044           99281           140574\n",
       "25        0        0      64664          139553           137962\n",
       "26        1        0      75328          144135           134050\n",
       "27        0        1      72107          127864           353183\n",
       "28        1        0      66051          182645           118148\n",
       "29        0        1      65605          153032           107138\n",
       "30        1        0      61994          115641            91131\n",
       "31        0        1      61136          152701            88218\n",
       "32        0        0      63408          129219            46085\n",
       "33        1        0      55493          103057           214634\n",
       "34        0        0      46426          157693           210797\n",
       "35        0        1      46014           85047           205517\n",
       "36        1        0      28663          127056           201126\n",
       "37        0        0      44069           51283           197029\n",
       "38        0        1      20229           65947           185265\n",
       "39        0        0      38558           82982           174999\n",
       "40        0        0      28754          118546           172795\n",
       "41        1        0      27892           84710           164470\n",
       "42        0        0      23640           96189           148001\n",
       "43        0        1      15505          127382            35534\n",
       "44        0        0      22177          154806            28334\n",
       "45        0        1       1000          124153             1903\n",
       "46        1        0       1315          115816           297114\n",
       "47        0        0          0          135426                0\n",
       "48        0        1        542           51743                0\n",
       "49        0        0          0          116983            45173"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df1_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73305bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df1_x=np.append(arr=np.ones((50,1)).astype(int),values=encoded_df1_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a103d6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,      0,      1, 165349, 136897, 471784],\n",
       "       [     1,      0,      0, 162597, 151377, 443898],\n",
       "       [     1,      1,      0, 153441, 101145, 407934],\n",
       "       [     1,      0,      1, 144372, 118671, 383199],\n",
       "       [     1,      1,      0, 142107,  91391, 366168],\n",
       "       [     1,      0,      1, 131876,  99814, 362861],\n",
       "       [     1,      0,      0, 134615, 147198, 127716],\n",
       "       [     1,      1,      0, 130298, 145530, 323876],\n",
       "       [     1,      0,      1, 120542, 148718, 311613],\n",
       "       [     1,      0,      0, 123334, 108679, 304981],\n",
       "       [     1,      1,      0, 101913, 110594, 229160],\n",
       "       [     1,      0,      0, 100671,  91790, 249744],\n",
       "       [     1,      1,      0,  93863, 127320, 249839],\n",
       "       [     1,      0,      0,  91992, 135495, 252664],\n",
       "       [     1,      1,      0, 119943, 156547, 256512],\n",
       "       [     1,      0,      1, 114523, 122616, 261776],\n",
       "       [     1,      0,      0,  78013, 121597, 264346],\n",
       "       [     1,      0,      1,  94657, 145077, 282574],\n",
       "       [     1,      1,      0,  91749, 114175, 294919],\n",
       "       [     1,      0,      1,  86419, 153514,      0],\n",
       "       [     1,      0,      0,  76253, 113867, 298664],\n",
       "       [     1,      0,      1,  78389, 153773, 299737],\n",
       "       [     1,      1,      0,  73994, 122782, 303319],\n",
       "       [     1,      1,      0,  67532, 105751, 304768],\n",
       "       [     1,      0,      1,  77044,  99281, 140574],\n",
       "       [     1,      0,      0,  64664, 139553, 137962],\n",
       "       [     1,      1,      0,  75328, 144135, 134050],\n",
       "       [     1,      0,      1,  72107, 127864, 353183],\n",
       "       [     1,      1,      0,  66051, 182645, 118148],\n",
       "       [     1,      0,      1,  65605, 153032, 107138],\n",
       "       [     1,      1,      0,  61994, 115641,  91131],\n",
       "       [     1,      0,      1,  61136, 152701,  88218],\n",
       "       [     1,      0,      0,  63408, 129219,  46085],\n",
       "       [     1,      1,      0,  55493, 103057, 214634],\n",
       "       [     1,      0,      0,  46426, 157693, 210797],\n",
       "       [     1,      0,      1,  46014,  85047, 205517],\n",
       "       [     1,      1,      0,  28663, 127056, 201126],\n",
       "       [     1,      0,      0,  44069,  51283, 197029],\n",
       "       [     1,      0,      1,  20229,  65947, 185265],\n",
       "       [     1,      0,      0,  38558,  82982, 174999],\n",
       "       [     1,      0,      0,  28754, 118546, 172795],\n",
       "       [     1,      1,      0,  27892,  84710, 164470],\n",
       "       [     1,      0,      0,  23640,  96189, 148001],\n",
       "       [     1,      0,      1,  15505, 127382,  35534],\n",
       "       [     1,      0,      0,  22177, 154806,  28334],\n",
       "       [     1,      0,      1,   1000, 124153,   1903],\n",
       "       [     1,      1,      0,   1315, 115816, 297114],\n",
       "       [     1,      0,      0,      0, 135426,      0],\n",
       "       [     1,      0,      1,    542,  51743,      0],\n",
       "       [     1,      0,      0,      0, 116983,  45173]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df1_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc42db9",
   "metadata": {},
   "source": [
    "Step: 2:\n",
    "\n",
    "Now, we are actually going to apply a backward elimination process. Firstly we will create a new feature vector x_opt, which will only contain a set of independent features that are significantly affecting the dependent variable.\n",
    "Next, as per the Backward Elimination process, we need to choose a significant level(0.5), and then need to fit the model with all possible predictors. So for fitting the model, we will create a regressor_OLS object of new class OLS of statsmodels library. Then we will fit it by using the fit() method.\n",
    "Next we need p-value to compare with SL value, so for this we will use summary() method to get the summary table of all the values. Below is the code for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "790a9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df1_x = encoded_df1_x.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5da23130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,      0,      1, 165349, 136897, 471784],\n",
       "       [     1,      0,      0, 162597, 151377, 443898],\n",
       "       [     1,      1,      0, 153441, 101145, 407934],\n",
       "       [     1,      0,      1, 144372, 118671, 383199],\n",
       "       [     1,      1,      0, 142107,  91391, 366168],\n",
       "       [     1,      0,      1, 131876,  99814, 362861],\n",
       "       [     1,      0,      0, 134615, 147198, 127716],\n",
       "       [     1,      1,      0, 130298, 145530, 323876],\n",
       "       [     1,      0,      1, 120542, 148718, 311613],\n",
       "       [     1,      0,      0, 123334, 108679, 304981],\n",
       "       [     1,      1,      0, 101913, 110594, 229160],\n",
       "       [     1,      0,      0, 100671,  91790, 249744],\n",
       "       [     1,      1,      0,  93863, 127320, 249839],\n",
       "       [     1,      0,      0,  91992, 135495, 252664],\n",
       "       [     1,      1,      0, 119943, 156547, 256512],\n",
       "       [     1,      0,      1, 114523, 122616, 261776],\n",
       "       [     1,      0,      0,  78013, 121597, 264346],\n",
       "       [     1,      0,      1,  94657, 145077, 282574],\n",
       "       [     1,      1,      0,  91749, 114175, 294919],\n",
       "       [     1,      0,      1,  86419, 153514,      0],\n",
       "       [     1,      0,      0,  76253, 113867, 298664],\n",
       "       [     1,      0,      1,  78389, 153773, 299737],\n",
       "       [     1,      1,      0,  73994, 122782, 303319],\n",
       "       [     1,      1,      0,  67532, 105751, 304768],\n",
       "       [     1,      0,      1,  77044,  99281, 140574],\n",
       "       [     1,      0,      0,  64664, 139553, 137962],\n",
       "       [     1,      1,      0,  75328, 144135, 134050],\n",
       "       [     1,      0,      1,  72107, 127864, 353183],\n",
       "       [     1,      1,      0,  66051, 182645, 118148],\n",
       "       [     1,      0,      1,  65605, 153032, 107138],\n",
       "       [     1,      1,      0,  61994, 115641,  91131],\n",
       "       [     1,      0,      1,  61136, 152701,  88218],\n",
       "       [     1,      0,      0,  63408, 129219,  46085],\n",
       "       [     1,      1,      0,  55493, 103057, 214634],\n",
       "       [     1,      0,      0,  46426, 157693, 210797],\n",
       "       [     1,      0,      1,  46014,  85047, 205517],\n",
       "       [     1,      1,      0,  28663, 127056, 201126],\n",
       "       [     1,      0,      0,  44069,  51283, 197029],\n",
       "       [     1,      0,      1,  20229,  65947, 185265],\n",
       "       [     1,      0,      0,  38558,  82982, 174999],\n",
       "       [     1,      0,      0,  28754, 118546, 172795],\n",
       "       [     1,      1,      0,  27892,  84710, 164470],\n",
       "       [     1,      0,      0,  23640,  96189, 148001],\n",
       "       [     1,      0,      1,  15505, 127382,  35534],\n",
       "       [     1,      0,      0,  22177, 154806,  28334],\n",
       "       [     1,      0,      1,   1000, 124153,   1903],\n",
       "       [     1,      1,      0,   1315, 115816, 297114],\n",
       "       [     1,      0,      0,      0, 135426,      0],\n",
       "       [     1,      0,      1,    542,  51743,      0],\n",
       "       [     1,      0,      0,      0, 116983,  45173]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df1_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49588eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Jun 2023</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:25:50</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.855</td> <td>    7.281</td> <td> 0.000</td> <td> 3.63e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7542</td> <td> 3371.026</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.103</td> <td> 6992.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -42.0063</td> <td> 3256.058</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.161</td> <td> 6520.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.368</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.783</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.945   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     169.9   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Jun 2023 & \\textbf{  Prob (F-statistic):} &  1.34e-27   \\\\\n",
       "\\textbf{Time:}             &     22:25:50     & \\textbf{  Log-Likelihood:    } &   -525.38   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Residuals:}     &          44      & \\textbf{  BIC:               } &     1074.   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.013e+04  &     6884.855     &     7.281  &         0.000        &     3.63e+04    &      6.4e+04     \\\\\n",
       "\\textbf{x1}    &     198.7542  &     3371.026     &     0.059  &         0.953        &    -6595.103    &     6992.611     \\\\\n",
       "\\textbf{x2}    &     -42.0063  &     3256.058     &    -0.013  &         0.990        &    -6604.161    &     6520.148     \\\\\n",
       "\\textbf{x3}    &       0.8060  &        0.046     &    17.368  &         0.000        &        0.712    &        0.900     \\\\\n",
       "\\textbf{x4}    &      -0.0270  &        0.052     &    -0.517  &         0.608        &       -0.132    &        0.078     \\\\\n",
       "\\textbf{x5}    &       0.0270  &        0.017     &     1.574  &         0.123        &       -0.008    &        0.062     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.783 & \\textbf{  Durbin-Watson:     } &    1.283  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.267  \\\\\n",
       "\\textbf{Skew:}          & -0.948 & \\textbf{  Prob(JB):          } & 2.41e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.572 & \\textbf{  Cond. No.          } & 1.45e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.45e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Mon, 19 Jun 2023   Prob (F-statistic):           1.34e-27\n",
       "Time:                        22:25:50   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.855      7.281      0.000    3.63e+04     6.4e+04\n",
       "x1           198.7542   3371.026      0.059      0.953   -6595.103    6992.611\n",
       "x2           -42.0063   3256.058     -0.013      0.990   -6604.161    6520.148\n",
       "x3             0.8060      0.046     17.368      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.783   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.267\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=encoded_df1_x[:,[0,1,2,3,4,5]]\n",
    "regressor_OLS=smf.OLS(endog=y,exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd4aa6",
   "metadata": {},
   "source": [
    "From the table, we will choose the highest p-value, which is for x1=0.953 Now, we have the highest p-value which is greater than the SL value, so will remove the x1 variable (dummy variable) from the table and will refit the model. Below is the code for it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b98d139a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Jun 2023</td> <th>  Prob (F-statistic):</th> <td>8.50e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:25:50</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.018e+04</td> <td> 6747.657</td> <td>    7.437</td> <td> 0.000</td> <td> 3.66e+04</td> <td> 6.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -136.6070</td> <td> 2801.735</td> <td>   -0.049</td> <td> 0.961</td> <td>-5779.592</td> <td> 5506.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8059</td> <td>    0.046</td> <td>   17.571</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0269</td> <td>    0.052</td> <td>   -0.521</td> <td> 0.605</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0271</td> <td>    0.017</td> <td>    1.625</td> <td> 0.111</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.892</td> <th>  Durbin-Watson:     </th> <td>   1.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>1.97e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.608</td> <th>  Cond. No.          </th> <td>1.43e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.43e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.946   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     217.2   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Jun 2023 & \\textbf{  Prob (F-statistic):} &  8.50e-29   \\\\\n",
       "\\textbf{Time:}             &     22:25:50     & \\textbf{  Log-Likelihood:    } &   -525.38   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1061.   \\\\\n",
       "\\textbf{Df Residuals:}     &          45      & \\textbf{  BIC:               } &     1070.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.018e+04  &     6747.657     &     7.437  &         0.000        &     3.66e+04    &     6.38e+04     \\\\\n",
       "\\textbf{x1}    &    -136.6070  &     2801.735     &    -0.049  &         0.961        &    -5779.592    &     5506.378     \\\\\n",
       "\\textbf{x2}    &       0.8059  &        0.046     &    17.571  &         0.000        &        0.714    &        0.898     \\\\\n",
       "\\textbf{x3}    &      -0.0269  &        0.052     &    -0.521  &         0.605        &       -0.131    &        0.077     \\\\\n",
       "\\textbf{x4}    &       0.0271  &        0.017     &     1.625  &         0.111        &       -0.007    &        0.061     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.892 & \\textbf{  Durbin-Watson:     } &    1.284  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.666  \\\\\n",
       "\\textbf{Skew:}          & -0.949 & \\textbf{  Prob(JB):          } & 1.97e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.608 & \\textbf{  Cond. No.          } & 1.43e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.43e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Mon, 19 Jun 2023   Prob (F-statistic):           8.50e-29\n",
       "Time:                        22:25:50   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.018e+04   6747.657      7.437      0.000    3.66e+04    6.38e+04\n",
       "x1          -136.6070   2801.735     -0.049      0.961   -5779.592    5506.378\n",
       "x2             0.8059      0.046     17.571      0.000       0.714       0.898\n",
       "x3            -0.0269      0.052     -0.521      0.605      -0.131       0.077\n",
       "x4             0.0271      0.017      1.625      0.111      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.892   Durbin-Watson:                   1.284\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.666\n",
       "Skew:                          -0.949   Prob(JB):                     1.97e-05\n",
       "Kurtosis:                       5.608   Cond. No.                     1.43e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.43e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=encoded_df1_x[:, [0,2,3,4,5]]  \n",
    "regressor_OLS=smf.OLS(endog = y, exog=x_opt).fit()  \n",
    "regressor_OLS.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b62401e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Jun 2023</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:25:50</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.384</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.839</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.587</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.948   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     296.0   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Jun 2023 & \\textbf{  Prob (F-statistic):} &  4.53e-30   \\\\\n",
       "\\textbf{Time:}             &     22:25:50     & \\textbf{  Log-Likelihood:    } &   -525.39   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1059.   \\\\\n",
       "\\textbf{Df Residuals:}     &          46      & \\textbf{  BIC:               } &     1066.   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.012e+04  &     6572.384     &     7.626  &         0.000        &     3.69e+04    &     6.34e+04     \\\\\n",
       "\\textbf{x1}    &       0.8057  &        0.045     &    17.846  &         0.000        &        0.715    &        0.897     \\\\\n",
       "\\textbf{x2}    &      -0.0268  &        0.051     &    -0.526  &         0.602        &       -0.130    &        0.076     \\\\\n",
       "\\textbf{x3}    &       0.0272  &        0.016     &     1.655  &         0.105        &       -0.006    &        0.060     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.839 & \\textbf{  Durbin-Watson:     } &    1.282  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.443  \\\\\n",
       "\\textbf{Skew:}          & -0.949 & \\textbf{  Prob(JB):          } & 2.21e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.587 & \\textbf{  Cond. No.          } & 1.40e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Mon, 19 Jun 2023   Prob (F-statistic):           4.53e-30\n",
       "Time:                        22:25:50   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.384      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.839   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.443\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.587   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=encoded_df1_x[:, [0,3,4,5]]  \n",
    "regressor_OLS=smf.OLS(endog = y, exog=x_opt).fit()  \n",
    "regressor_OLS.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9db75727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Jun 2023</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:25:50</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.941</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.265</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.678</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.950   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.948   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     450.8   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Jun 2023 & \\textbf{  Prob (F-statistic):} &  2.16e-31   \\\\\n",
       "\\textbf{Time:}             &     22:25:50     & \\textbf{  Log-Likelihood:    } &   -525.54   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1057.   \\\\\n",
       "\\textbf{Df Residuals:}     &          47      & \\textbf{  BIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    4.698e+04  &     2689.941     &    17.464  &         0.000        &     4.16e+04    &     5.24e+04     \\\\\n",
       "\\textbf{x1}    &       0.7966  &        0.041     &    19.265  &         0.000        &        0.713    &        0.880     \\\\\n",
       "\\textbf{x2}    &       0.0299  &        0.016     &     1.927  &         0.060        &       -0.001    &        0.061     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.678 & \\textbf{  Durbin-Watson:     } &    1.257  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.162  \\\\\n",
       "\\textbf{Skew:}          & -0.939 & \\textbf{  Prob(JB):          } & 2.54e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.575 & \\textbf{  Cond. No.          } & 5.32e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 5.32e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Mon, 19 Jun 2023   Prob (F-statistic):           2.16e-31\n",
       "Time:                        22:25:50   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.941     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.265      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.678   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.162\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=encoded_df1_x[:, [0,3,5]]  \n",
    "regressor_OLS=smf.OLS(endog = y, exog=x_opt).fit()  \n",
    "regressor_OLS.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62bf307a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Jun 2023</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:25:50</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.900</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.43e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.947   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.945   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     849.8   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Jun 2023 & \\textbf{  Prob (F-statistic):} &  3.50e-32   \\\\\n",
       "\\textbf{Time:}             &     22:25:50     & \\textbf{  Log-Likelihood:    } &   -527.44   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1059.   \\\\\n",
       "\\textbf{Df Residuals:}     &          48      & \\textbf{  BIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    4.903e+04  &     2537.900     &    19.320  &         0.000        &     4.39e+04    &     5.41e+04     \\\\\n",
       "\\textbf{x1}    &       0.8543  &        0.029     &    29.151  &         0.000        &        0.795    &        0.913     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 13.727 & \\textbf{  Durbin-Watson:     } &    1.116  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   18.538  \\\\\n",
       "\\textbf{Skew:}          & -0.911 & \\textbf{  Prob(JB):          } & 9.43e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.361 & \\textbf{  Cond. No.          } & 1.65e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.65e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Mon, 19 Jun 2023   Prob (F-statistic):           3.50e-32\n",
       "Time:                        22:25:50   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.900     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.538\n",
       "Skew:                          -0.911   Prob(JB):                     9.43e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=encoded_df1_x[:, [0,3]]  \n",
    "regressor_OLS=smf.OLS(endog = y, exog=x_opt).fit()  \n",
    "regressor_OLS.summary()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af693c5c",
   "metadata": {},
   "source": [
    "As we can see in the above output image, only two variables are left. So only the R&D independent variable is a significant variable for the prediction. So we can now predict efficiently using this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b189ef",
   "metadata": {},
   "source": [
    "Below is the code for Building Multiple Linear Regression model by only using R&D spend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8835836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "add82bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=pd.read_csv('50_Startups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15c5622b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a28617b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BE=data_set.iloc[:,0]\n",
    "y_BE=data_set.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de9e4d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    165349.20\n",
       "1    162597.70\n",
       "2    153441.51\n",
       "3    144372.41\n",
       "4    142107.34\n",
       "Name: R&D Spend, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_BE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2de512fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    192261.83\n",
       "1    191792.06\n",
       "2    191050.39\n",
       "3    182901.99\n",
       "4    166187.94\n",
       "Name: Profit, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_BE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d1e85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_BE_train,x_BE_test,y_BE_train,y_BE_test=train_test_split(x_BE,y_BE,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d272d7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the MLR model to training test\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "regressor= LinearRegression()  \n",
    "regressor.fit(np.array(x_BE_train).reshape(-1,1), y_BE_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63fe0e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33    55493.95\n",
       "35    46014.02\n",
       "26    75328.87\n",
       "34    46426.07\n",
       "18    91749.16\n",
       "Name: R&D Spend, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_BE_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9c9a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the test set result\n",
    "y_pred= regressor.predict(np.array(x_BE_train).reshape(-1,1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "560c9c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9449589778363044\n",
      "Test Score: 0.9464587607787219\n"
     ]
    }
   ],
   "source": [
    "# Checking the score\n",
    "print('Train Score:',regressor.score(np.array(x_BE_train).reshape(-1,1), y_BE_train))\n",
    "print('Test Score:',regressor.score(np.array(x_BE_test).reshape(-1,1), y_BE_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273b5d5",
   "metadata": {},
   "source": [
    "As we can see, the training score is 94% accurate, and the test score is also 94% accurate. The difference between both scores is .00149."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
